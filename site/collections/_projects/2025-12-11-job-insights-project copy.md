---
date: 2025-12-11 05:20:35 +0300
title: UK data job market insights v1
subtitle: Serverless ETL using Python Azure Functions, SQL, Power Query, DAX & Power BI.
image: '/images/job-insights-hero.png'
hide_image: true
---
<div style="text-align: center;">
<iframe title="Jobs 1" width="700" height="500"  src="https://app.powerbi.com/view?r=eyJrIjoiMGVhYTAxNjgtOTFiMy00MzVkLWJlYzMtMDIzZDI5N2NkOGFkIiwidCI6IjVkNWVkNWRjLTE1YTctNDljMi05OWU2LWQzYmQ1NzY0YjM1NiJ9&pageName=801249cc78928d02bb84" frameborder="0" allowFullScreen="true"></iframe>
</div>
---

## Project background

With this project, I wanted to both demonstrate a broad range of data and BI skills and gain practical insights into the job market to support my own career transition.

---

## Data selection

Initially, I considered using sample datasets from Kaggle or Hugging Face, but after researching publicly available options, the Reed.co.uk API stood out as a richer, more realistic source for a project centred around analytics, ETL, and reporting.

---

## ğŸ—ï¸ Architecture

![Jobs Pipeline](/images/jobs-pipeline.svg)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Reed.co.uk API â”‚  â† HTTP Basic Auth, 4-key rotation, rate-limit handling
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ fetch (pagination & incremental filtering)
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  landing.raw_jobs (JSONB raw)   â”‚  â† Raw API responses, content hashing
â”‚  Deduplication via composite PK â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ transform & enrich (Python ETL)
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  staging.jobs_v1 (flattened)     â”‚  â† Normalized schema, skill extraction
â”‚  Enriched metadata & seniority   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”˜
         â”‚                       â”‚
         â–¼                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ staging.fact_jobsâ”‚  â”‚ staging.job_skills â”‚  â† Many-to-many junction table
â”‚ Materialized w/  â”‚  â”‚ 60+ canonical skillsâ”‚
â”‚ dimensional keys â”‚  â”‚ + categories        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Power BI/Fabric â”‚  â† Interactive dashboards & analytics
â”‚   Analytics     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## âœ¨ Key Features & Capabilities

### ğŸ”Œ Robust API Integration
- **4-tier API key rotation** with round-robin load balancing
- **Intelligent rate-limit handling** (403 errors â†’ automatic fallback)
- **Adaptive retry logic** with exponential backoff (500/502/503 errors)
- **Incremental ingestion** (configurable lookback window: fetch only jobs posted in last N days)
- **Content-hash change detection** (MD5 hashing prevents unnecessary reprocessing)

### ğŸ” Smart Data Enrichment
- **Auto-fetches full job descriptions** from detail endpoint (works around Reed's 453-char truncation)
- **Description validation** detects truncation patterns and validates completeness
- **60+ canonical skills extraction** with regex patterns and normalization (e.g., `postgres` â†’ `postgresql`, `k8s` â†’ `kubernetes`)
- **Skill categorization**: Programming Languages, Databases, Cloud/DevOps, ML, BI, Tools
- **Seniority detection**: Executive/Director/Manager/Lead/Senior/Mid/Junior/Entry
- **Work location classification**: Remote, Hybrid, Office
- **Employment type extraction**: Full-time, Part-time, Contract
- **Job role categorization**: Engineering, Analyst, Scientist, Architect

### ğŸ§¹ Intelligent Filtering & Quality
- **Rule-based title filtering** with word-boundary matching (configurable include/exclude lists)
- **Optional ML classifier** (TF-IDF + Naive Bayes) for advanced job relevance scoring
- **Deduplication** via composite primary keys at every layer
- **Expired job cleanup** (automatic removal based on expiration dates)
- **Data quality metrics** (enrichment rate, description validation, duplicate detection)
- **Blacklist support** for permanently excluded job IDs

### ğŸ’° Salary Normalization & Analytics
- **Salary annualization** converts all salary types to annual figures:
  - `per week` Ã— 52 weeks/year
  - `per day` Ã— 260 working days/year  
  - `per hour` Ã— 1,950 working hours/year
- **Dynamic salary bands**: Â£0â€“9,999, Â£10kâ€“19,999, ..., capped at Â£540kâ€“549,999
- **Original value preservation** (`*_old` columns for audit trail)
- Enables consistent cross-title salary comparisons

### ğŸ“Š Dimensional Data Warehouse
- **Star schema design** with fact and dimension tables
- **Materialized analytics table** (`fact_jobs`) with pre-computed dimensional keys
- **10+ dimension tables**: Salary bands, employers, locations, seniority, contracts, skills, etc.
- **Indexed for performance** (primary keys + salary band index)
- **Atomic UPSERT operations** (ON CONFLICT pattern with temp tables)
- **Batch processing** (500â€“1,000 rows per insert for optimal throughput)

---

## ğŸ› ï¸ Technical Stack

| Layer | Technology | Purpose |
|-------|------------|---------|
| **Language** | Python 3.x | ETL logic, data transformations |
| **Cloud Platform** | Azure Functions | Serverless compute (timer-triggered) |
| **Database** | PostgreSQL | Data warehouse (Azure Database for PostgreSQL) |
| **API Client** | `requests` | HTTP client with authentication |
| **Data Processing** | `psycopg2` | PostgreSQL driver with batch operations |
| **ML (Optional)** | `scikit-learn` | TF-IDF + Naive Bayes job classifier |
| **Visualization** | Power BI / Microsoft Fabric | Interactive dashboards |
| **Deployment** | Azure | Managed infrastructure |

---

## ğŸ“ Project Structure

```
jobs-pipeline/
â”œâ”€â”€ function_app.py              # Azure Functions entry point (timer trigger)
â”œâ”€â”€ run_pipeline.py              # Local test runner for development
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ local.settings.json          # Environment configuration (gitignored)
â”‚
â”œâ”€â”€ reed_ingest/                 # Main ETL module (2,500+ lines)
â”‚   â””â”€â”€ __init__.py              â”œâ”€ API client with 4-key rotation
â”‚                                â”œâ”€ Skill extraction & categorization
â”‚                                â”œâ”€ Title filtering (rule-based + ML)
â”‚                                â”œâ”€ Salary annualization logic
â”‚                                â”œâ”€ Seniority/location/employment detection
â”‚                                â”œâ”€ Data quality monitoring
â”‚                                â””â”€ Database UPSERT operations
â”‚
â”œâ”€â”€ job_classifier.py            # TF-IDF + Naive Bayes ML classifier (optional)
â”‚
â”œâ”€â”€ sql/                         # Database schema definitions
â”‚   â”œâ”€â”€ fact_jobs.sql            â”œâ”€ Materialized analytics table
â”‚   â”œâ”€â”€ fact_job_skill.sql       â”œâ”€ Job-skill junction table
â”‚   â”œâ”€â”€ dim_salaryband.sql       â”œâ”€ Dynamic salary bands
â”‚   â”œâ”€â”€ dim_employer.sql         â”œâ”€ Employer dimension
â”‚   â”œâ”€â”€ dim_location.sql         â”œâ”€ Location dimension
â”‚   â”œâ”€â”€ dim_seniority.sql        â”œâ”€ Seniority levels
â”‚   â”œâ”€â”€ dim_skill.sql            â”œâ”€ Canonical skills
â”‚   â””â”€â”€ ...                      â””â”€ Other dimensions
â”‚
â”œâ”€â”€ docs/                        # Project documentation
â”‚   â”œâ”€â”€ project_structure.md     â”œâ”€ Repository organization
â”‚   â”œâ”€â”€ duplication_prevention.mdâ”œâ”€ Data quality strategies
â”‚   â””â”€â”€ recent_changes.md        â””â”€ Change log
â”‚
â””â”€â”€ powerbi/                     # Power BI visualizations
    â””â”€â”€ README.md
```

---

## ğŸ”„ Data Flow

### 1ï¸âƒ£ Extract (API Ingestion)
- **Fetch jobs** from Reed.co.uk API with pagination (50â€“100 results per page)
- **Incremental filtering** (only jobs posted in last N days via `postedByDays` parameter)
- **Round-robin key rotation** distributes load across 4 API keys
- **Rate-limit handling** automatically falls back to backup keys on 403 errors
- **Store raw JSON** in `landing.raw_jobs` with content hash for change detection

### 2ï¸âƒ£ Transform (Data Enrichment)
- **Title filtering** applies include/exclude rules with word-boundary matching
- **Skill extraction** identifies 60+ canonical skills from descriptions
- **Skill normalization** maps variations to standard names (e.g., `powerbi` â†’ `power bi`)
- **Seniority detection** infers level from title/description keywords
- **Work location classification** determines remote/hybrid/office
- **Salary annualization** converts all salary types to annual figures
- **Job role categorization** assigns Engineering/Analyst/Scientist/Architect

### 3ï¸âƒ£ Load (Database Operations)
- **Atomic UPSERT** to `staging.jobs_v1` via temp table pattern
- **Batch inserts** (500â€“1,000 rows per operation)
- **Skill extraction** to `staging.job_skills` junction table
- **Dimension population** (employers, locations, seniority, etc.)
- **Fact table materialization** (`fact_jobs`) with pre-computed dimensional keys

### 4ï¸âƒ£ Analytics (Power BI)
- **Direct Query** or **Import mode** connections to PostgreSQL
- **Pre-computed metrics** (days open, apps/day, competition analysis)
- **Dimensional analysis** (salary bands, seniority, skills, locations)
- **Interactive dashboards** with filters and drill-downs

---

## ğŸ“Š Database Schema

### Landing Layer
**`landing.raw_jobs`** - Raw API responses
```sql
CREATE TABLE landing.raw_jobs (
    source_name     TEXT,           -- 'reed'
    job_id          TEXT,           -- Reed job ID
    raw             JSONB,          -- Complete API JSON
    content_hash    TEXT,           -- MD5 for change detection
    posted_at       TIMESTAMPTZ,
    expires_at      TIMESTAMPTZ,
    ingested_at     TIMESTAMPTZ,
    PRIMARY KEY (source_name, job_id)
);
```

### Staging Layer
**`staging.jobs_v1`** - Normalized job records
```sql
CREATE TABLE staging.jobs_v1 (
    staging_id          BIGSERIAL PRIMARY KEY,
    source_name         TEXT,
    job_id              TEXT,
    job_title           TEXT,
    employer_name       TEXT,
    location_name       TEXT,
    salary_min          NUMERIC,        -- Annualized
    salary_max          NUMERIC,        -- Annualized
    salary_type         TEXT,
    work_location_type  TEXT,           -- remote/hybrid/office
    seniority_level     TEXT,
    job_role_category   TEXT,
    contract_type       TEXT,
    full_time           BOOLEAN,
    part_time           BOOLEAN,
    job_description     TEXT,           -- Full enriched text
    posted_at           TIMESTAMPTZ,
    expires_at          TIMESTAMPTZ,
    UNIQUE (source_name, job_id)
);
```

**`staging.job_skills`** - Job-to-skill mappings
```sql
CREATE TABLE staging.job_skills (
    id              BIGSERIAL PRIMARY KEY,
    source_name     TEXT,
    job_id          TEXT,
    skill           TEXT,               -- Canonical skill name
    category        TEXT,               -- programming_languages, databases, etc.
    matched_pattern TEXT,               -- Original variation matched
    UNIQUE (source_name, job_id, skill)
);
```

### Analytics Layer
**`staging.fact_jobs`** - Materialized analytics table (indexed)
- All job attributes + pre-computed dimensional keys
- Salary bands, employer keys, location keys, etc.
- Computed metrics: `days_open`, `apps_per_day`, `is_active`
- Indexed on `salaryband_key` for fast filtering

**Dimension Tables** (10+ tables)
- `dim_salaryband` - Dynamic Â£10k-width bands (Â£0â€“Â£549,999, capped)
- `dim_employer` - Employer master data
- `dim_location` - Location + work type (remote/hybrid/office)
- `dim_seniority` - Seniority levels
- `dim_contract` - Contract types
- `dim_skill` - Canonical skill names
- `dim_source` - Data sources (Reed, etc.)
- `dim_ageband` - Job age bands
- `dim_demandband` - Application volume bands
- `dim_jobtype` - Role categories

---

## âš™ï¸ Configuration

All settings are environment-driven via `local.settings.json`:

```json
{
  "Values": {
    "API_KEY": "your-reed-api-key",
    "API_KEY_BACKUP": "backup-key-1",
    "API_KEY_BACKUP_2": "backup-key-2",
    "API_KEY_BACKUP_3": "backup-key-3",
    "API_BASE_URL": "https://www.reed.co.uk/api/1.0/search",
    "SEARCH_KEYWORDS": "data,bi,analyst,microsoft fabric",
    "RESULTS_PER_PAGE": 100,
    "POSTED_BY_DAYS": 30,
    "MAX_RESULTS": 0,
    "JOB_TITLE_INCLUDE": "data,bi,analyst,microsoft fabric",
    "JOB_TITLE_EXCLUDE": "trainee,intern,apprentice,asbestos,...",
    "USE_ML_CLASSIFIER": "false",
    "ML_CLASSIFIER_THRESHOLD": "0.7",
    "PGHOST": "your-postgres-server.postgres.database.azure.com",
    "PGPORT": "5432",
    "PGDATABASE": "jobs_warehouse",
    "PGUSER": "admin",
    "PGPASSWORD": "****",
    "PGSSLMODE": "require"
  }
}
```

---

## ğŸš€ Running the Pipeline

### Local Development
```bash
# Install dependencies
pip install -r requirements.txt

# Configure settings
cp local.settings.json.example local.settings.json
# Edit local.settings.json with your API keys and database credentials

# Run pipeline locally
python run_pipeline.py
```

### Azure Deployment
```bash
# Deploy to Azure Functions
func azure functionapp publish <your-function-app-name>

# Scheduled execution (daily at midnight UTC)
# Configured in function_app.py: @app.timer_trigger(schedule="0 0 0 * * *")
```

---

## ğŸ“ˆ Key Metrics & Performance

### Current System Stats
- **Total jobs processed**: 2,791 unique postings
- **Staging layer**: 2,552 jobs (after filtering)
- **Skills extracted**: 60+ canonical skills across 6 categories
- **Dimensions**: 10+ dimensional tables
- **Deduplication**: 0 duplicates across all layers
- **Enrichment rate**: >95% full descriptions fetched

### Performance Optimizations
- âœ… **Indexed queries** (primary keys + salary band index)
- âœ… **Materialized fact table** (eliminates expensive joins)
- âœ… **Batch inserts** (500â€“1,000 rows per operation)
- âœ… **Atomic transactions** (temp table pattern for consistency)
- âœ… **Content-hash caching** (avoids unnecessary reprocessing)
- âœ… **Round-robin key rotation** (distributes API load evenly)

---

## ğŸ“ Skills Demonstrated

### Data Engineering
- âœ… **ETL Pipeline Design** - End-to-end data flow from API to warehouse
- âœ… **API Integration** - Rate limiting, retry logic, authentication
- âœ… **Data Warehousing** - Star schema, dimensional modeling, indexing
- âœ… **Data Quality** - Deduplication, validation, change detection
- âœ… **Performance Optimization** - Batch processing, materialized views, indexing

### Python Development
- âœ… **Clean Code** - Modular design, type hints, docstrings
- âœ… **Error Handling** - Robust exception management, logging
- âœ… **Testing** - Local test runner for development
- âœ… **Configuration Management** - Environment-driven settings

### Database Engineering
- âœ… **PostgreSQL** - DDL, DML, CTEs, window functions
- âœ… **Schema Design** - Normalization, foreign keys, constraints
- âœ… **Query Optimization** - Indexes, materialized views, batch operations
- âœ… **ACID Transactions** - Atomic operations, consistency guarantees

### Cloud & DevOps
- âœ… **Azure Functions** - Serverless compute, timer triggers
- âœ… **Azure Database for PostgreSQL** - Managed database service
- âœ… **CI/CD** - Automated deployment pipeline
- âœ… **Security** - Secrets management, SSL connections

### Analytics & BI
- âœ… **Power BI** - Dashboard design, DAX measures, data modeling
- âœ… **Dimensional Modeling** - Star schema, fact/dimension tables
- âœ… **Business Metrics** - KPIs, trends, competitive analysis

---

## ğŸ“ Lessons Learned

### âœ… Successes
- **Robust API integration** handles rate limits gracefully with 4-key rotation
- **Content hashing** prevents unnecessary reprocessing (40%+ API call reduction)
- **Atomic temp-table pattern** eliminates mid-batch failures and duplicates
- **Salary annualization** enables accurate cross-title comparisons
- **Materialized fact table** dramatically improves Power BI query performance

### ğŸ”§ Challenges Overcome
- **Reed API description truncation** (453 chars) â†’ solved with detail endpoint fetching
- **Rate limiting** (403 errors) â†’ solved with 4-tier fallback and round-robin rotation
- **Mid-batch failures** â†’ solved with atomic temp-table pattern
- **Skill normalization** â†’ solved with alias mapping and regex patterns
- **Salary comparison** â†’ solved with annualization logic

---
